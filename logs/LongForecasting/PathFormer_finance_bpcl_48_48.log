Args in experiment:
Namespace(is_training=1, model='PathFormer', model_id='finance_bpcl_48_48', data='custom', root_path='./dataset/finance', data_path='BPCL.csv', features='MS', target='Close', freq='d', checkpoints='./checkpoints/', seq_len=48, pred_len=48, individual=False, d_model=8, d_ff=64, num_nodes=9, layer_nums=3, k=2, num_experts_list=[4, 4, 4], patch_size_list=[[16, 12, 8, 4], [12, 8, 6, 4], [8, 6, 2, 12]], do_predict=False, revin=1, drop=0.1, embed='timeF', residual_connection=1, metric='mae', batch_norm=0, num_workers=10, itr=1, train_epochs=15, batch_size=32, patience=10, learning_rate=0.001, lradj='TST', use_amp=False, pct_start=0.4, use_gpu=False, gpu=0, use_multi_gpu=False, devices='2', test_flop=False)
Use CPU
>>>>>>>start training : finance_bpcl_48_48_PathFormer_BPCL_ftMS_sl48_pl48_0>>>>>>>>>>>>>>>>>>>>>>>>>>
 DATA LOADED FROM DATA_LOADER 
          date  Prev Close    Open    High  ...    VWAP  Volume      Turnover   Close
0  03-01-2000      381.20  405.00  407.00  ...  399.32    8720  3.482030e+11  399.25
1  04-01-2000      399.25  397.75  397.75  ...  375.71   22820  8.573700e+11  370.50
2  05-01-2000      370.50  350.00  385.00  ...  359.96  152538  5.490790e+12  359.95
3  06-01-2000      359.95  362.00  384.00  ...  380.10   59554  2.263620e+12  380.30
4  07-01-2000      380.30  369.00  390.00  ...  378.33   43187  1.633890e+12  379.85

[5 rows x 10 columns]
after adjusting cols 
      Prev Close    Open    High  ...    Volume      Turnover    Close
0         381.20  405.00  407.00  ...      8720  3.482030e+11   399.25
1         399.25  397.75  397.75  ...     22820  8.573700e+11   370.50
2         370.50  350.00  385.00  ...    152538  5.490790e+12   359.95
3         359.95  362.00  384.00  ...     59554  2.263620e+12   380.30
4         380.30  369.00  390.00  ...     43187  1.633890e+12   379.85
...          ...     ...     ...  ...       ...           ...      ...
5301      423.05  426.00  428.35  ...   6444098  2.715060e+14  5026.80
5302      418.90  417.50  423.10  ...   5408165  2.273850e+14  5044.20
5303      420.35  422.00  424.35  ...   9902533  4.152460e+14  5010.00
5304      417.50  422.00  423.00  ...   6632804  2.785770e+14  5034.60
5305      419.55  417.50  437.50  ...  16851470  7.214720e+14  5061.60

[5306 rows x 9 columns]
after scaling the data 
 [[-9.38860996e-02  5.84599493e-02  2.01456191e-02 ... -8.91078482e-01
  -8.22248254e-01 -1.02874541e+00]
 [ 2.51979611e-02  1.07042966e-02 -4.00313811e-02 ... -8.75390966e-01
  -8.09549070e-01 -1.08670603e+00]
 [-1.64478867e-01 -3.03824313e-01 -1.22978057e-01 ... -7.31068041e-01
  -6.93986481e-01 -1.10797506e+00]
 ...
 [ 1.64404259e-01  1.70438721e-01  1.33018154e-01 ...  1.01166770e+01
   9.52575894e+00  8.26662604e+00]
 [ 1.45601513e-01  1.70438721e-01  1.24235565e-01 ...  6.47880986e+00
   6.11708383e+00  8.31622017e+00]
 [ 1.59126295e-01  1.40797282e-01  2.18567079e-01 ...  1.78479935e+01
   1.71633720e+01  8.37065275e+00]]
3714
train 3619
x data after scaling 
[[-0.0938861   0.05845995  0.02014562 ... -0.89107848 -0.82224825
  -1.02874541]
 [ 0.02519796  0.0107043  -0.04003138 ... -0.87539097 -0.80954907
  -1.08670603]
 [-0.16447887 -0.30382431 -0.12297806 ... -0.73106804 -0.69398648
  -1.10797506]
 ...
 [ 2.15155767  2.18539792  2.11625691 ...  0.26608167  1.05416286
   3.97088728]
 [ 2.14001213  2.13204333  2.14423108 ... -0.13539636  0.41347091
   4.00838528]
 [ 2.17069029  2.13336072  2.13382209 ...  0.2566725   1.04289697
   3.96766165]]
len of sample data 9

3714
3714
 DATA LOADED FROM DATA_LOADER 
          date  Prev Close    Open    High  ...    VWAP  Volume      Turnover   Close
0  03-01-2000      381.20  405.00  407.00  ...  399.32    8720  3.482030e+11  399.25
1  04-01-2000      399.25  397.75  397.75  ...  375.71   22820  8.573700e+11  370.50
2  05-01-2000      370.50  350.00  385.00  ...  359.96  152538  5.490790e+12  359.95
3  06-01-2000      359.95  362.00  384.00  ...  380.10   59554  2.263620e+12  380.30
4  07-01-2000      380.30  369.00  390.00  ...  378.33   43187  1.633890e+12  379.85

[5 rows x 10 columns]
after adjusting cols 
      Prev Close    Open    High  ...    Volume      Turnover    Close
0         381.20  405.00  407.00  ...      8720  3.482030e+11   399.25
1         399.25  397.75  397.75  ...     22820  8.573700e+11   370.50
2         370.50  350.00  385.00  ...    152538  5.490790e+12   359.95
3         359.95  362.00  384.00  ...     59554  2.263620e+12   380.30
4         380.30  369.00  390.00  ...     43187  1.633890e+12   379.85
...          ...     ...     ...  ...       ...           ...      ...
5301      423.05  426.00  428.35  ...   6444098  2.715060e+14  5026.80
5302      418.90  417.50  423.10  ...   5408165  2.273850e+14  5044.20
5303      420.35  422.00  424.35  ...   9902533  4.152460e+14  5010.00
5304      417.50  422.00  423.00  ...   6632804  2.785770e+14  5034.60
5305      419.55  417.50  437.50  ...  16851470  7.214720e+14  5061.60

[5306 rows x 9 columns]
after scaling the data 
 [[-9.38860996e-02  5.84599493e-02  2.01456191e-02 ... -8.91078482e-01
  -8.22248254e-01 -1.02874541e+00]
 [ 2.51979611e-02  1.07042966e-02 -4.00313811e-02 ... -8.75390966e-01
  -8.09549070e-01 -1.08670603e+00]
 [-1.64478867e-01 -3.03824313e-01 -1.22978057e-01 ... -7.31068041e-01
  -6.93986481e-01 -1.10797506e+00]
 ...
 [ 1.64404259e-01  1.70438721e-01  1.33018154e-01 ...  1.01166770e+01
   9.52575894e+00  8.26662604e+00]
 [ 1.45601513e-01  1.70438721e-01  1.24235565e-01 ...  6.47880986e+00
   6.11708383e+00  8.31622017e+00]
 [ 1.59126295e-01  1.40797282e-01  2.18567079e-01 ...  1.78479935e+01
   1.71633720e+01  8.37065275e+00]]
579
val 484
x data after scaling 
[[2.00971239 2.03455592 1.97150683 ... 0.27224208 1.00308349 3.75194734]
 [1.96089123 1.92125976 1.87815116 ... 0.18430743 0.83103979 3.62493798]
 [1.85698131 1.85341379 1.86969385 ... 0.53046528 1.36270172 3.66122637]
 ...
 [1.74746356 1.7513155  1.70510162 ... 0.96047679 1.92286385 8.82546722]
 [1.75142203 1.7513155  1.7226668  ... 0.26642991 0.89887708 8.79966214]
 [1.7408661  1.77041776 1.69794544 ... 0.41817604 1.10977154 8.77305066]]
len of sample data 9

579
579
 DATA LOADED FROM DATA_LOADER 
          date  Prev Close    Open    High  ...    VWAP  Volume      Turnover   Close
0  03-01-2000      381.20  405.00  407.00  ...  399.32    8720  3.482030e+11  399.25
1  04-01-2000      399.25  397.75  397.75  ...  375.71   22820  8.573700e+11  370.50
2  05-01-2000      370.50  350.00  385.00  ...  359.96  152538  5.490790e+12  359.95
3  06-01-2000      359.95  362.00  384.00  ...  380.10   59554  2.263620e+12  380.30
4  07-01-2000      380.30  369.00  390.00  ...  378.33   43187  1.633890e+12  379.85

[5 rows x 10 columns]
after adjusting cols 
      Prev Close    Open    High  ...    Volume      Turnover    Close
0         381.20  405.00  407.00  ...      8720  3.482030e+11   399.25
1         399.25  397.75  397.75  ...     22820  8.573700e+11   370.50
2         370.50  350.00  385.00  ...    152538  5.490790e+12   359.95
3         359.95  362.00  384.00  ...     59554  2.263620e+12   380.30
4         380.30  369.00  390.00  ...     43187  1.633890e+12   379.85
...          ...     ...     ...  ...       ...           ...      ...
5301      423.05  426.00  428.35  ...   6444098  2.715060e+14  5026.80
5302      418.90  417.50  423.10  ...   5408165  2.273850e+14  5044.20
5303      420.35  422.00  424.35  ...   9902533  4.152460e+14  5010.00
5304      417.50  422.00  423.00  ...   6632804  2.785770e+14  5034.60
5305      419.55  417.50  437.50  ...  16851470  7.214720e+14  5061.60

[5306 rows x 9 columns]
after scaling the data 
 [[-9.38860996e-02  5.84599493e-02  2.01456191e-02 ... -8.91078482e-01
  -8.22248254e-01 -1.02874541e+00]
 [ 2.51979611e-02  1.07042966e-02 -4.00313811e-02 ... -8.75390966e-01
  -8.09549070e-01 -1.08670603e+00]
 [-1.64478867e-01 -3.03824313e-01 -1.22978057e-01 ... -7.31068041e-01
  -6.93986481e-01 -1.10797506e+00]
 ...
 [ 1.64404259e-01  1.70438721e-01  1.33018154e-01 ...  1.01166770e+01
   9.52575894e+00  8.26662604e+00]
 [ 1.45601513e-01  1.70438721e-01  1.24235565e-01 ...  6.47880986e+00
   6.11708383e+00  8.31622017e+00]
 [ 1.59126295e-01  1.40797282e-01  2.18567079e-01 ...  1.78479935e+01
   1.71633720e+01  8.37065275e+00]]
1109
test 1014
x data after scaling 
[[ 1.74614407  1.71838057  1.7174623  ...  0.63296706  1.4408796
   8.81982236]
 [ 1.74911292  1.57346686  1.72461849 ...  1.21354535  2.25091413
   8.81014546]
 [ 1.74515445  1.72826105  1.75031569 ...  1.63547501  2.95614865
   8.88433505]
 ...
 [ 0.16440426  0.17043872  0.13301815 ... 10.11667701  9.52575894
   8.26662604]
 [ 0.14560151  0.17043872  0.12423557 ...  6.47880986  6.11708383
   8.31622017]
 [ 0.1591263   0.14079728  0.21856708 ... 17.84799349 17.16337205
   8.37065275]]
len of sample data 9

3714
3714
3714
3714
	iters: 100, epoch: 1 | loss: 0.2006722
	speed: 1.8054s/iter; left time: 2881.3487s
Epoch: 1 cost time: 191.44755053520203
579
579
579
1109
Epoch: 1, Steps: 113 | Train Loss: 0.2969324 Vali Loss: 0.5847166 Test Loss: 1.1281548
Validation loss decreased (inf --> 0.584717).  Saving model ...
Updating learning rate to 0.00010449354896379227
3714
3714
3714
	iters: 100, epoch: 2 | loss: 0.2101429
	speed: 2.2732s/iter; left time: 3371.1189s
Epoch: 2 cost time: 129.78455257415771
579
579
579
1109
Epoch: 2, Steps: 113 | Train Loss: 0.2084457 Vali Loss: 0.5220534 Test Loss: 0.9284884
Validation loss decreased (0.584717 --> 0.522053).  Saving model ...
Updating learning rate to 0.00028064328811373113
3714
3714
3714
	iters: 100, epoch: 3 | loss: 0.1602059
	speed: 2.4815s/iter; left time: 3399.6494s
Epoch: 3 cost time: 141.46204352378845
579
579
579
1109
Epoch: 3, Steps: 113 | Train Loss: 0.1834478 Vali Loss: 0.4777540 Test Loss: 0.9050300
Validation loss decreased (0.522053 --> 0.477754).  Saving model ...
Updating learning rate to 0.0005211137098380424
3714
3714
3714
	iters: 100, epoch: 4 | loss: 0.1559301
	speed: 2.6193s/iter; left time: 3292.4128s
Epoch: 4 cost time: 129.20017552375793
579
579
579
1109
Epoch: 4, Steps: 113 | Train Loss: 0.1733486 Vali Loss: 0.4900443 Test Loss: 0.8610395
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0007612848519791403
3714
3714
3714
	iters: 100, epoch: 5 | loss: 0.1695397
	speed: 2.5397s/iter; left time: 2905.4329s
Epoch: 5 cost time: 138.40730237960815
579
579
579
1109
Epoch: 5, Steps: 113 | Train Loss: 0.1686029 Vali Loss: 0.4826067 Test Loss: 0.8489293
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0009366171757229962
3714
3714
3714
	iters: 100, epoch: 6 | loss: 0.1925536
	speed: 1.6136s/iter; left time: 1663.5761s
Epoch: 6 cost time: 88.92279624938965
579
579
579
1109
Epoch: 6, Steps: 113 | Train Loss: 0.1657326 Vali Loss: 0.4862489 Test Loss: 0.8452517
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0009999976144102194
3714
3714
3714
	iters: 100, epoch: 7 | loss: 0.1493314
	speed: 1.5565s/iter; left time: 1428.8392s
Epoch: 7 cost time: 92.4533019065857
579
579
579
1109
Epoch: 7, Steps: 113 | Train Loss: 0.1638461 Vali Loss: 0.4698704 Test Loss: 0.8679582
Validation loss decreased (0.477754 --> 0.469870).  Saving model ...
Updating learning rate to 0.0009693159287345636
3714
3714
3714
	iters: 100, epoch: 8 | loss: 0.1636357
	speed: 1.5406s/iter; left time: 1240.1972s
Epoch: 8 cost time: 86.90934443473816
579
579
579
1109
Epoch: 8, Steps: 113 | Train Loss: 0.1626011 Vali Loss: 0.4648603 Test Loss: 0.8570893
Validation loss decreased (0.469870 --> 0.464860).  Saving model ...
Updating learning rate to 0.000882028056917607
3714
3714
3714
	iters: 100, epoch: 9 | loss: 0.1683091
	speed: 1.5183s/iter; left time: 1050.6814s
Epoch: 9 cost time: 88.92993760108948
579
579
579
1109
Epoch: 9, Steps: 113 | Train Loss: 0.1617939 Vali Loss: 0.4726442 Test Loss: 0.8367498
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0007486622045322618
3714
3714
3714
	iters: 100, epoch: 10 | loss: 0.1419399
	speed: 1.6659s/iter; left time: 964.5805s
Epoch: 10 cost time: 102.21446204185486
579
579
579
1109
Epoch: 10, Steps: 113 | Train Loss: 0.1607870 Vali Loss: 0.4605408 Test Loss: 0.8592394
Validation loss decreased (0.464860 --> 0.460541).  Saving model ...
Updating learning rate to 0.0005853042616465551
3714
3714
3714
	iters: 100, epoch: 11 | loss: 0.1830406
	speed: 1.5200s/iter; left time: 708.3211s
Epoch: 11 cost time: 85.72443699836731
579
579
579
1109
Epoch: 11, Steps: 113 | Train Loss: 0.1600498 Vali Loss: 0.4671866 Test Loss: 0.8368579
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0004116576070789717
3714
3714
3714
	iters: 100, epoch: 12 | loss: 0.1503815
	speed: 1.5096s/iter; left time: 532.8994s
Epoch: 12 cost time: 89.28952288627625
579
579
579
1109
Epoch: 12, Steps: 113 | Train Loss: 0.1592539 Vali Loss: 0.4620047 Test Loss: 0.8482946
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0002486665901220424
3714
3714
3714
	iters: 100, epoch: 13 | loss: 0.1784369
	speed: 1.5725s/iter; left time: 377.4008s
Epoch: 13 cost time: 93.53375840187073
579
579
579
1109
Epoch: 13, Steps: 113 | Train Loss: 0.1576552 Vali Loss: 0.4696812 Test Loss: 0.8491148
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00011599033291199156
3714
3714
3714
	iters: 100, epoch: 14 | loss: 0.1508012
	speed: 1.5329s/iter; left time: 194.6774s
Epoch: 14 cost time: 87.19237327575684
579
579
579
1109
Epoch: 14, Steps: 113 | Train Loss: 0.1581220 Vali Loss: 0.4663874 Test Loss: 0.8461053
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9631550161364563e-05
3714
3714
3714
	iters: 100, epoch: 15 | loss: 0.1358465
	speed: 1.5159s/iter; left time: 21.2229s
Epoch: 15 cost time: 89.55642890930176
579
579
579
1109
Epoch: 15, Steps: 113 | Train Loss: 0.1573582 Vali Loss: 0.4669470 Test Loss: 0.8454236
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.3855897806319944e-09
>>>>>>>testing : finance_bpcl_48_48_PathFormer_BPCL_ftMS_sl48_pl48_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
 DATA LOADED FROM DATA_LOADER 
          date  Prev Close    Open    High  ...    VWAP  Volume      Turnover   Close
0  03-01-2000      381.20  405.00  407.00  ...  399.32    8720  3.482030e+11  399.25
1  04-01-2000      399.25  397.75  397.75  ...  375.71   22820  8.573700e+11  370.50
2  05-01-2000      370.50  350.00  385.00  ...  359.96  152538  5.490790e+12  359.95
3  06-01-2000      359.95  362.00  384.00  ...  380.10   59554  2.263620e+12  380.30
4  07-01-2000      380.30  369.00  390.00  ...  378.33   43187  1.633890e+12  379.85

[5 rows x 10 columns]
after adjusting cols 
      Prev Close    Open    High  ...    Volume      Turnover    Close
0         381.20  405.00  407.00  ...      8720  3.482030e+11   399.25
1         399.25  397.75  397.75  ...     22820  8.573700e+11   370.50
2         370.50  350.00  385.00  ...    152538  5.490790e+12   359.95
3         359.95  362.00  384.00  ...     59554  2.263620e+12   380.30
4         380.30  369.00  390.00  ...     43187  1.633890e+12   379.85
...          ...     ...     ...  ...       ...           ...      ...
5301      423.05  426.00  428.35  ...   6444098  2.715060e+14  5026.80
5302      418.90  417.50  423.10  ...   5408165  2.273850e+14  5044.20
5303      420.35  422.00  424.35  ...   9902533  4.152460e+14  5010.00
5304      417.50  422.00  423.00  ...   6632804  2.785770e+14  5034.60
5305      419.55  417.50  437.50  ...  16851470  7.214720e+14  5061.60

[5306 rows x 9 columns]
after scaling the data 
 [[-9.38860996e-02  5.84599493e-02  2.01456191e-02 ... -8.91078482e-01
  -8.22248254e-01 -1.02874541e+00]
 [ 2.51979611e-02  1.07042966e-02 -4.00313811e-02 ... -8.75390966e-01
  -8.09549070e-01 -1.08670603e+00]
 [-1.64478867e-01 -3.03824313e-01 -1.22978057e-01 ... -7.31068041e-01
  -6.93986481e-01 -1.10797506e+00]
 ...
 [ 1.64404259e-01  1.70438721e-01  1.33018154e-01 ...  1.01166770e+01
   9.52575894e+00  8.26662604e+00]
 [ 1.45601513e-01  1.70438721e-01  1.24235565e-01 ...  6.47880986e+00
   6.11708383e+00  8.31622017e+00]
 [ 1.59126295e-01  1.40797282e-01  2.18567079e-01 ...  1.78479935e+01
   1.71633720e+01  8.37065275e+00]]
1109
test 1014
x data after scaling 
[[ 1.74614407  1.71838057  1.7174623  ...  0.63296706  1.4408796
   8.81982236]
 [ 1.74911292  1.57346686  1.72461849 ...  1.21354535  2.25091413
   8.81014546]
 [ 1.74515445  1.72826105  1.75031569 ...  1.63547501  2.95614865
   8.88433505]
 ...
 [ 0.16440426  0.17043872  0.13301815 ... 10.11667701  9.52575894
   8.26662604]
 [ 0.14560151  0.17043872  0.12423557 ...  6.47880986  6.11708383
   8.31622017]
 [ 0.1591263   0.14079728  0.21856708 ... 17.84799349 17.16337205
   8.37065275]]
len of sample data 9

1109
(992, 48, 1)
(992, 48, 1)
1.9771244376897812
mse:17394.11328125, mae:95.13143157958984, rse:0.1698683798313141 ,mape : 1.9771244376897812
Inference time:  35.138577461242676
